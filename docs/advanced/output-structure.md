# Output Structure

This page explains the organization of output files generated by the LLM Smoke Test Framework.

## Overview

The framework generates multiple types of output files, including extracted page data, analysis results, screenshots, and test scripts. These files are organized in a structured directory layout to keep everything well-organized and easy to find.

## Default Output Directory

By default, all output is saved to the `output` directory in the project root. You can customize this location using the `--output` option or the `OUTPUT_DIR` environment variable.

## Output Organization Modes

The framework organizes output differently based on the mode you're using:

### Single Page Mode

When analyzing individual pages (default mode), the output is organized as follows:

```
output/
├── analysis/           # Analysis results
│   └── example.com_login_analysis.json
├── page_data/          # Extracted page data
│   └── example.com_login_data.json
├── screenshots/        # Captured screenshots
│   └── example.com_login.jpg
└── test_scripts/       # Generated test scripts
    ├── login/          # Scripts organized by page type
    │   ├── LoginPage.java
    │   ├── login.feature
    │   └── LoginSteps.java
    └── other_page_types/
```

### Site-Wide Mode

When using site-wide testing (`--site` flag), the output includes a timestamp to support multiple runs:

```
output/
├── site_e2e_example.com_20250423_124255/      # Site-specific directory with timestamp
│   ├── analysis/                              # Site-specific analysis results
│   │   ├── example.com_login_analysis.json
│   │   ├── example.com_register_analysis.json
│   │   └── ...
│   ├── page_data/                             # Site-specific extracted page data
│   │   ├── example.com_login_data.json
│   │   ├── example.com_register_data.json
│   │   └── ...
│   ├── screenshots/                           # Site-specific screenshots
│   │   ├── example.com_login.jpg
│   │   ├── example.com_register.jpg
│   │   └── ...
│   ├── test_scripts/                          # Site-specific test scripts
│   │   └── batch_1/                           # Test scripts organized in batches
│   │       ├── login/                         # Scripts organized by page type
│   │       │   ├── LoginPage.java
│   │       │   ├── login.feature
│   │       │   └── LoginSteps.java
│   │       ├── form/
│   │       └── landing/
│   └── sitemap.json                           # Site structure information
├── site_e2e_anothersite.com_20250423_130455/  # Another site analysis
└── ...
```

## Output File Types

### Page Data Files

Page data files (in the `page_data` directory) contain the raw data extracted from web pages:

```json
{
  "url": "https://example.com/login",
  "title": "Login - Example Site",
  "html": "<!DOCTYPE html>...",
  "screenshot_path": "output/screenshots/example.com_login.jpg",
  "interactive_elements": [
    {"type": "input", "id": "username", "attributes": {...}},
    {"type": "input", "id": "password", "attributes": {...}},
    {"type": "button", "id": "login-button", "attributes": {...}}
  ],
  "links": [...],
  "forms": [...],
  "metadata": {...},
  "timestamp": "2025-04-23T12:42:55"
}
```

### Analysis Result Files

Analysis result files (in the `analysis` directory) contain the LLM's analysis of the page:

```json
{
  "page_url": "https://example.com/login",
  "page_type": "login",
  "interactive_elements": [...],
  "suggested_scenarios": [
    {
      "name": "Successful login with valid credentials",
      "steps": [...]
    },
    {
      "name": "Failed login with invalid credentials",
      "steps": [...]
    }
  ],
  "form_fields": [...],
  "buttons": [...],
  "links": [...],
  "assertions": [...],
  "metadata": {...},
  "timestamp": "2025-04-23T12:43:10"
}
```

### Generated Test Scripts

Test scripts are organized by page type in the `test_scripts` directory. For Cucumber/Java output:

1. **Feature Files** (`*.feature`): Contain Cucumber scenarios in Gherkin syntax
2. **Step Definition Files** (`*Steps.java`): Contain Java implementations of step definitions
3. **Page Object Files** (`*Page.java`): Contain page object classes for better test organization

For example, a feature file might look like:

```gherkin
Feature: Login Page Tests

  Scenario: Successful login with valid credentials
    Given I am on the login page
    When I enter "testuser" in the username field
    And I enter "password123" in the password field
    And I click the "Login" button
    Then I should be redirected to the dashboard
    And I should see a welcome message

  Scenario: Failed login with invalid credentials
    Given I am on the login page
    When I enter "invaliduser" in the username field
    And I enter "wrongpassword" in the password field
    And I click the "Login" button
    Then I should see an error message
    And I should remain on the login page
```

### Sitemap Files

For site-wide testing, a `sitemap.json` file is generated with information about the site structure:

```json
{
  "base_url": "https://example.com",
  "pages": [
    {
      "url": "https://example.com/",
      "title": "Homepage",
      "links": ["https://example.com/login", "https://example.com/products", ...]
    },
    {
      "url": "https://example.com/login",
      "title": "Login",
      "links": ["https://example.com/", "https://example.com/register", ...]
    },
    ...
  ],
  "crawl_info": {
    "start_time": "2025-04-23T12:40:00",
    "end_time": "2025-04-23T12:45:30",
    "pages_crawled": 15,
    "max_depth": 2
  }
}
```

## Customizing Output

You can customize how output is organized:

### Custom Output Directory

```bash
python run.py vision-e2e https://example.com --output custom_dir
```

### Controlling What's Saved

```bash
python run.py vision-e2e https://example.com --no-save-screenshots --no-save-analysis
```

### Custom Output Structure (Experimental)

```bash
python run.py vision-e2e https://example.com --output-structure flat
```

## Output Management

Over time, the output directory can grow large, especially with site-wide testing. Consider these management strategies:

1. **Regular Cleanup**: Delete old site runs you no longer need
2. **Archive Important Runs**: Archive important test runs for reference
3. **Gitignore**: Add the output directory to your `.gitignore` file to avoid committing large files
4. **Environment-Specific Directories**: Use different output directories for different environments

## Using Generated Tests

The generated test scripts are ready to use in your test projects:

1. **Copy to Test Project**: Copy the relevant test scripts to your test project
2. **Install Dependencies**: Install Selenium, Cucumber, etc. as needed
3. **Run with Test Runner**: Use your preferred test runner to execute the tests

For Cucumber Java, you might run:

```bash
mvn test -Dcucumber.options="--tags @login"
```
