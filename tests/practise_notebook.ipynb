{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTISE: TEST THE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config/config.py\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration for the LLM Smoke Test Framework.\"\"\"\n",
    "\n",
    "    # Crawler settings\n",
    "    HEADLESS: bool = True\n",
    "    PAGE_LOAD_TIMEOUT: int = 30\n",
    "    CAPTURE_SCREENSHOTS: bool = True\n",
    "    ANALYZE_LAYOUT: bool = True\n",
    "    CHROME_DRIVER_PATH: Optional[str] = None\n",
    "\n",
    "    # Output settings\n",
    "    OUTPUT_DIR: str = \"output\"\n",
    "    BASE_URL: str = \"\"  # Base URL for the application under test\n",
    "\n",
    "    # LLM settings\n",
    "    OPENAI_API_KEY: Optional[str] = None\n",
    "    LLM_MODEL: str = \"gpt-4o-mini\"  # Using non-vision model\n",
    "    LLM_TEMPERATURE: float = 0.0\n",
    "    LLM_MAX_TOKENS: int = 500  # Further reduced for split analysis\n",
    "    LLM_MAX_CONTEXT: int = 8000  # Maximum context size for mini model\n",
    "    VISUAL_ANALYSIS_TOKENS: int = 300  # Specific limit for visual analysis\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Load configuration from environment variables.\"\"\"\n",
    "        # Load from environment variables\n",
    "        self.OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", self.OPENAI_API_KEY)\n",
    "        self.CHROME_DRIVER_PATH = os.getenv(\n",
    "            \"CHROME_DRIVER_PATH\", self.CHROME_DRIVER_PATH\n",
    "        )\n",
    "        self.OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\", self.OUTPUT_DIR)\n",
    "        self.BASE_URL = os.getenv(\"BASE_URL\", self.BASE_URL)\n",
    "        self.LLM_MODEL = os.getenv(\"LLM_MODEL\", self.LLM_MODEL)\n",
    "        self.LLM_TEMPERATURE = float(\n",
    "            os.getenv(\"LLM_TEMPERATURE\", str(self.LLM_TEMPERATURE))\n",
    "        )\n",
    "        self.LLM_MAX_TOKENS = int(os.getenv(\"LLM_MAX_TOKENS\", str(self.LLM_MAX_TOKENS)))\n",
    "\n",
    "        # Create output directories\n",
    "        self._create_output_directories()\n",
    "\n",
    "        self.validate()\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Validate configuration.\"\"\"\n",
    "        if not self.OPENAI_API_KEY:\n",
    "            raise ValueError(\"OPENAI_API_KEY must be set\")\n",
    "\n",
    "    def _create_output_directories(self):\n",
    "        \"\"\"Create all required output directories.\"\"\"\n",
    "        directories = {\n",
    "            \"page_data_path\": os.path.join(self.OUTPUT_DIR, \"page_data\"),\n",
    "            \"analysis_path\": os.path.join(self.OUTPUT_DIR, \"analysis\"),\n",
    "            \"test_scripts_path\": os.path.join(self.OUTPUT_DIR, \"test_scripts\"),\n",
    "            \"screenshots_path\": os.path.join(self.OUTPUT_DIR, \"screenshots\"),\n",
    "        }\n",
    "\n",
    "        for path in directories.values():\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        # Add directory paths as properties\n",
    "        for name, path in directories.items():\n",
    "            setattr(self, name, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, Any, Optional\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# from config.config import Config # refer above section in this notebook\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebCrawler:\n",
    "    \"\"\"Web crawler for extracting page data for testing.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"Initialize the web crawler.\n",
    "\n",
    "        Args:\n",
    "            config (Config): Configuration object\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.driver = None\n",
    "        self._initialize_driver()\n",
    "\n",
    "    def _initialize_driver(self):\n",
    "        \"\"\"Initialize the Selenium WebDriver.\"\"\"\n",
    "        try:\n",
    "            options = Options()\n",
    "            if self.config.HEADLESS:\n",
    "                options.add_argument('--headless')\n",
    "            options.add_argument('--no-sandbox')\n",
    "            options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "            if self.config.CHROME_DRIVER_PATH:\n",
    "                service = Service(executable_path=self.config.CHROME_DRIVER_PATH)\n",
    "                self.driver = webdriver.Chrome(service=service, options=options)\n",
    "            else:\n",
    "                self.driver = webdriver.Chrome(options=options)\n",
    "\n",
    "            self.driver.set_page_load_timeout(self.config.PAGE_LOAD_TIMEOUT)\n",
    "            logger.info(\"WebDriver initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize WebDriver: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def extract_page_data(self, url: str, with_screenshots: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract data from a webpage.\n",
    "\n",
    "        Args:\n",
    "            url (str): URL to crawl\n",
    "            with_screenshots (bool): Whether to capture screenshots\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: Extracted page data\n",
    "        \"\"\"\n",
    "        if not self.driver:\n",
    "            self._initialize_driver()\n",
    "\n",
    "        logger.info(f\"Crawling URL: {url}\")\n",
    "        try:\n",
    "            # Load page\n",
    "            self.driver.get(url)\n",
    "            try:\n",
    "                WebDriverWait(self.driver, self.config.PAGE_LOAD_TIMEOUT).until(\n",
    "                    lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Timeout waiting for page to load: {str(e)}\")\n",
    "\n",
    "            # Initialize page data\n",
    "            page_data = {\n",
    "                \"url\": url,\n",
    "                \"title\": self.driver.title,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"elements\": [],\n",
    "                \"forms\": [],\n",
    "                \"frames\": [],\n",
    "                \"headings\": []\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                # Extract elements and their attributes (limit to maximum of 100 important elements)\n",
    "                self._extract_elements(page_data)\n",
    "\n",
    "                # Only keep top N elements to avoid token limits\n",
    "                if len(page_data[\"elements\"]) > 100:\n",
    "                    # Sort by importance\n",
    "                    page_data[\"elements\"].sort(\n",
    "                        key=lambda e: (\n",
    "                            e.get(\"tag\") in [\"button\", \"a\", \"input\", \"select\", \"textarea\"],  # Interactive first\n",
    "                            bool(e.get(\"id\", \"\")),  # Then with ID\n",
    "                            bool(e.get(\"name\", \"\")),  # Then with name\n",
    "                            bool(e.get(\"text\", \"\"))  # Then with text\n",
    "                        ),\n",
    "                        reverse=True\n",
    "                    )\n",
    "                    # Keep only the top 100\n",
    "                    page_data[\"elements\"] = page_data[\"elements\"][:100]\n",
    "\n",
    "                # Extract frames\n",
    "                self._extract_frames(page_data)\n",
    "\n",
    "                # Extract form elements - very important for testing\n",
    "                self._extract_forms(page_data)\n",
    "\n",
    "                # Extract headings for page structure\n",
    "                self._extract_headings(page_data)\n",
    "\n",
    "                # Add selectors for elements\n",
    "                self._add_selectors_to_elements(page_data)\n",
    "\n",
    "                # Extract element relationships and hierarchy\n",
    "                self._extract_elements_with_hierarchy(page_data)\n",
    "\n",
    "                # Extract form relationships (labels, etc.)\n",
    "                self._extract_forms_with_relationships(page_data)\n",
    "\n",
    "                # Identify logical sections\n",
    "                self._identify_logical_sections(page_data)\n",
    "\n",
    "                # Capture screenshots if requested\n",
    "                if with_screenshots:\n",
    "                    self._capture_screenshots(page_data)\n",
    "\n",
    "                # Add HTML content (truncated to avoid token issues)\n",
    "                page_source = self.driver.page_source\n",
    "                if page_source:\n",
    "                    # Only include the first 100KB of HTML to avoid token limits\n",
    "                    page_data[\"html_content\"] = page_source[:100000] if len(page_source) > 100000 else page_source\n",
    "\n",
    "            except Exception as section_error:\n",
    "                logger.error(f\"Error extracting section data: {str(section_error)}\")\n",
    "\n",
    "            return page_data\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting page data from {url}: {str(e)}\")\n",
    "            return self._create_error_response(url, str(e))\n",
    "\n",
    "    def _extract_elements_with_hierarchy(self, page_data):\n",
    "        \"\"\"Extract page elements while preserving DOM hierarchy.\"\"\"\n",
    "        # Get the entire page DOM structure\n",
    "        dom_structure = {}\n",
    "\n",
    "        # Use JavaScript to get a hierarchical representation\n",
    "        script = \"\"\"\n",
    "        function getElementInfo(element) {\n",
    "            const result = {\n",
    "                tag: element.tagName.toLowerCase(),\n",
    "                id: element.id || null,\n",
    "                class: element.className || null,\n",
    "                type: element.type || null,\n",
    "                name: element.name || null,\n",
    "                text: element.textContent.trim() || null,\n",
    "                attributes: {},\n",
    "                children: []\n",
    "            };\n",
    "\n",
    "            // Get all attributes\n",
    "            for (let attr of element.attributes) {\n",
    "                result.attributes[attr.name] = attr.value;\n",
    "            }\n",
    "\n",
    "            // Get children elements (only interesting ones)\n",
    "            const interestingTags = ['div', 'form', 'button', 'a', 'input', 'select', 'textarea', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'label'];\n",
    "            for (let child of element.children) {\n",
    "                if (interestingTags.includes(child.tagName.toLowerCase())) {\n",
    "                    result.children.push(getElementInfo(child));\n",
    "                }\n",
    "            }\n",
    "\n",
    "            return result;\n",
    "        }\n",
    "\n",
    "        return getElementInfo(document.body);\n",
    "        \"\"\"\n",
    "\n",
    "        dom_structure = self.driver.execute_script(script)\n",
    "        page_data[\"dom_structure\"] = dom_structure\n",
    "\n",
    "    def _extract_forms_with_relationships(self, page_data):\n",
    "        \"\"\"Extract forms with their associated elements.\"\"\"\n",
    "        forms = self.driver.find_elements(By.TAG_NAME, \"form\")\n",
    "\n",
    "        page_data[\"forms\"] = []\n",
    "\n",
    "        for form in forms:\n",
    "            try:\n",
    "                form_data = {\n",
    "                    \"tag\": \"form\",\n",
    "                    \"id\": form.get_attribute(\"id\"),\n",
    "                    \"name\": form.get_attribute(\"name\"),\n",
    "                    \"action\": form.get_attribute(\"action\"),\n",
    "                    \"method\": form.get_attribute(\"method\"),\n",
    "                    \"elements\": []\n",
    "                }\n",
    "\n",
    "                # Extract all interactive elements in the form\n",
    "                for elem_type in [\"input\", \"select\", \"textarea\", \"button\"]:\n",
    "                    elements = form.find_elements(By.TAG_NAME, elem_type)\n",
    "                    for elem in elements:\n",
    "                        elem_data = {\n",
    "                            \"tag\": elem.tag_name,\n",
    "                            \"type\": elem.get_attribute(\"type\"),\n",
    "                            \"id\": elem.get_attribute(\"id\"),\n",
    "                            \"name\": elem.get_attribute(\"name\"),\n",
    "                            \"value\": elem.get_attribute(\"value\"),\n",
    "                            \"placeholder\": elem.get_attribute(\"placeholder\"),\n",
    "                        }\n",
    "\n",
    "                        # Add label text if there's an associated label\n",
    "                        if elem.get_attribute(\"id\"):\n",
    "                            label = self.driver.execute_script(\n",
    "                                f\"return document.querySelector('label[for=\\\"{elem.get_attribute('id')}\\\"]')?.textContent\"\n",
    "                            )\n",
    "                            if label:\n",
    "                                elem_data[\"label_text\"] = label.strip()\n",
    "\n",
    "                        form_data[\"elements\"].append(elem_data)\n",
    "\n",
    "                page_data[\"forms\"].append(form_data)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error extracting form: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    def _capture_screenshots(self, page_data):\n",
    "        \"\"\"Capture full page and element screenshots.\"\"\"\n",
    "\n",
    "        # Capture full page screenshot\n",
    "        screenshot_dir = os.path.join(self.config.OUTPUT_DIR, \"screenshots\")\n",
    "        os.makedirs(screenshot_dir, exist_ok=True)\n",
    "\n",
    "        # Generate a safe filename from URL\n",
    "        from urllib.parse import urlparse\n",
    "        import re\n",
    "        parsed_url = urlparse(page_data[\"url\"])\n",
    "        domain = parsed_url.netloc.replace(\".\", \"_\")\n",
    "        path = re.sub(r'[^\\w]', '_', parsed_url.path)\n",
    "        if not path:\n",
    "            path = \"home\"\n",
    "        filename = f\"{domain}_{path}.png\"\n",
    "\n",
    "        # Save full page screenshot\n",
    "        full_page_path = os.path.join(screenshot_dir, filename)\n",
    "        self.driver.save_screenshot(full_page_path)\n",
    "        page_data[\"screenshot_path\"] = full_page_path\n",
    "\n",
    "        # Optionally capture screenshots of key elements (forms, buttons, etc.)\n",
    "        element_screenshots = {}\n",
    "\n",
    "        # Capture form screenshots\n",
    "        for i, form in enumerate(self.driver.find_elements(By.TAG_NAME, \"form\")):\n",
    "            try:\n",
    "                form_name = form.get_attribute(\"id\") or form.get_attribute(\"name\") or f\"form_{i}\"\n",
    "                form_path = os.path.join(screenshot_dir, f\"{domain}_{path}_{form_name}.png\")\n",
    "                form.screenshot(form_path)\n",
    "                element_screenshots[f\"form_{i}\"] = form_path\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        page_data[\"element_screenshots\"] = element_screenshots\n",
    "\n",
    "    def _extract_elements(self, page_data: Dict[str, Any]):\n",
    "        \"\"\"Extract interactive elements from the page.\"\"\"\n",
    "        for elem_type, by_method in [\n",
    "            (\"button\", By.TAG_NAME),\n",
    "            (\"a\", By.TAG_NAME),\n",
    "            (\"input\", By.TAG_NAME),\n",
    "            (\"select\", By.TAG_NAME)\n",
    "        ]:\n",
    "            elements = self.driver.find_elements(by_method, elem_type)\n",
    "            for elem in elements:\n",
    "                try:\n",
    "                    element_data = {\n",
    "                        \"type\": elem_type,\n",
    "                        \"tag\": elem.tag_name\n",
    "                    }\n",
    "\n",
    "                    # Try to get various attributes\n",
    "                    for attr in [\"id\", \"name\", \"class\", \"type\", \"value\", \"placeholder\", \"href\"]:\n",
    "                        try:\n",
    "                            value = elem.get_attribute(attr)\n",
    "                            if value:\n",
    "                                element_data[attr] = value\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    # Get text content\n",
    "                    try:\n",
    "                        text = elem.text\n",
    "                        if text:\n",
    "                            element_data[\"text\"] = text\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # Add to elements list\n",
    "                    page_data[\"elements\"].append(element_data)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    def _extract_frames(self, page_data: Dict[str, Any]):\n",
    "        \"\"\"Extract frames from the page.\"\"\"\n",
    "        frames = self.driver.find_elements(By.TAG_NAME, \"iframe\")\n",
    "        for frame in frames:\n",
    "            try:\n",
    "                frame_data = {\"tag\": \"iframe\"}\n",
    "                for attr in [\"id\", \"name\", \"src\", \"width\", \"height\"]:\n",
    "                    value = frame.get_attribute(attr)\n",
    "                    if value:\n",
    "                        frame_data[attr] = value\n",
    "                page_data[\"frames\"].append(frame_data)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    def _extract_forms(self, page_data: Dict[str, Any]):\n",
    "        \"\"\"Extract forms from the page.\"\"\"\n",
    "        forms = self.driver.find_elements(By.TAG_NAME, \"form\")\n",
    "        for form in forms:\n",
    "            try:\n",
    "                form_data = {\n",
    "                    \"tag\": \"form\",\n",
    "                    \"inputs\": []\n",
    "                }\n",
    "\n",
    "                # Form attributes\n",
    "                for attr in [\"id\", \"name\", \"action\", \"method\"]:\n",
    "                    value = form.get_attribute(attr)\n",
    "                    if value:\n",
    "                        form_data[attr] = value\n",
    "\n",
    "                # Form inputs\n",
    "                inputs = form.find_elements(By.TAG_NAME, \"input\")\n",
    "                for input_elem in inputs:\n",
    "                    input_data = {}\n",
    "                    for attr in [\"id\", \"name\", \"type\", \"value\", \"placeholder\"]:\n",
    "                        value = input_elem.get_attribute(attr)\n",
    "                        if value:\n",
    "                            input_data[attr] = value\n",
    "                    if input_data:\n",
    "                        form_data[\"inputs\"].append(input_data)\n",
    "\n",
    "                page_data[\"forms\"].append(form_data)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    def _extract_headings(self, page_data: Dict[str, Any]):\n",
    "        \"\"\"Extract headings from the page.\"\"\"\n",
    "        for h_level in range(1, 7):\n",
    "            headings = self.driver.find_elements(By.TAG_NAME, f\"h{h_level}\")\n",
    "            for heading in headings:\n",
    "                try:\n",
    "                    heading_text = heading.text\n",
    "                    if heading_text:\n",
    "                        page_data[\"headings\"].append({\n",
    "                            \"level\": h_level,\n",
    "                            \"text\": heading_text\n",
    "                        })\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    def _create_error_response(self, url: str, error_msg: str) -> Dict[str, Any]:\n",
    "        \"\"\"Create an error response when page crawling fails.\"\"\"\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"title\": \"Error\",\n",
    "            \"error\": error_msg,\n",
    "            \"elements\": [],\n",
    "            \"frames\": [],\n",
    "            \"forms\": [],\n",
    "            \"headings\": []\n",
    "        }\n",
    "\n",
    "    def _add_selectors_to_elements(self, page_data):\n",
    "        \"\"\"Add XPath and CSS selectors to elements for better locators.\"\"\"\n",
    "\n",
    "        for element_type in [\"elements\", \"forms\"]:\n",
    "            for i, element in enumerate(page_data.get(element_type, [])):\n",
    "                try:\n",
    "                    # Generate a unique identifier for the element\n",
    "                    elem_id = element.get(\"id\") or element.get(\"name\")\n",
    "\n",
    "                    if elem_id:\n",
    "                        # Add CSS selector\n",
    "                        element[\"css_selector\"] = f\"#{elem_id}\" if element.get(\"id\") else f\"[name='{elem_id}']\"\n",
    "\n",
    "                        # Add XPath\n",
    "                        element[\"xpath\"] = f\"//*[@id='{element.get('id')}']\" if element.get(\"id\") else f\"//*[@name='{elem_id}']\"\n",
    "                    elif element.get(\"text\") and element.get(\"tag\"):\n",
    "                        # For elements with text but no ID/name\n",
    "                        element[\"xpath\"] = f\"//{element['tag']}[contains(text(), '{element['text']}')]\"\n",
    "\n",
    "                        # Try to create a more precise CSS selector\n",
    "                        if element.get(\"class\"):\n",
    "                            classes = element[\"class\"].split()\n",
    "                            if classes:\n",
    "                                element[\"css_selector\"] = f\"{element['tag']}.{classes[0]}\"\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    def _identify_logical_sections(self, page_data):\n",
    "        \"\"\"Identify logical sections/groups in the page.\"\"\"\n",
    "\n",
    "        # Use JavaScript to find logical sections based on semantic HTML\n",
    "        script = \"\"\"\n",
    "        function findLogicalSections() {\n",
    "            const sections = [];\n",
    "\n",
    "            // Find semantic sections\n",
    "            const semanticTags = [\n",
    "                'header', 'footer', 'main', 'nav', 'section', 'article',\n",
    "                'aside', 'form', 'div.container', 'div.section', 'div.row'\n",
    "            ];\n",
    "\n",
    "            semanticTags.forEach(selector => {\n",
    "                document.querySelectorAll(selector).forEach(element => {\n",
    "                    // Don't include elements that are too small or empty\n",
    "                    if (element.textContent.trim() &&\n",
    "                        element.getBoundingClientRect().width > 100 &&\n",
    "                        element.getBoundingClientRect().height > 50) {\n",
    "\n",
    "                        // Get heading if available\n",
    "                        let heading = '';\n",
    "                        const headingElem = element.querySelector('h1, h2, h3, h4, h5, h6');\n",
    "                        if (headingElem) {\n",
    "                            heading = headingElem.textContent.trim();\n",
    "                        }\n",
    "\n",
    "                        sections.push({\n",
    "                            tag: element.tagName.toLowerCase(),\n",
    "                            id: element.id || null,\n",
    "                            class: element.className || null,\n",
    "                            heading: heading,\n",
    "                            position: {\n",
    "                                x: element.getBoundingClientRect().x,\n",
    "                                y: element.getBoundingClientRect().y,\n",
    "                                width: element.getBoundingClientRect().width,\n",
    "                                height: element.getBoundingClientRect().height\n",
    "                            },\n",
    "                            elements: Array.from(element.querySelectorAll('button, a, input, select')).length\n",
    "                        });\n",
    "                    }\n",
    "                });\n",
    "            });\n",
    "\n",
    "            return sections;\n",
    "        }\n",
    "\n",
    "        return findLogicalSections();\n",
    "        \"\"\"\n",
    "\n",
    "        logical_sections = self.driver.execute_script(script)\n",
    "        page_data[\"logical_sections\"] = logical_sections\n",
    "\n",
    "    def crawl_with_user_flow(self, url, flow_description):\n",
    "        \"\"\"Crawl a page while simulating a user flow.\"\"\"\n",
    "\n",
    "        # First get the base page\n",
    "        page_data = self.extract_page_data(url)\n",
    "\n",
    "        # Parse the flow description and execute it\n",
    "        steps = flow_description.strip().split('\\n')\n",
    "\n",
    "        # Record the flow steps and their results\n",
    "        page_data[\"user_flow\"] = []\n",
    "\n",
    "        for step in steps:\n",
    "            try:\n",
    "                step = step.strip()\n",
    "                if not step:\n",
    "                    continue\n",
    "\n",
    "                step_result = {\"description\": step, \"success\": False}\n",
    "\n",
    "                # Parse the step and execute it\n",
    "                if step.startswith(\"click \"):\n",
    "                    element_desc = step[6:].strip()\n",
    "                    self._click_element(element_desc)\n",
    "                    step_result[\"success\"] = True\n",
    "\n",
    "                elif step.startswith(\"type \"):\n",
    "                    parts = step[5:].strip().split(\" into \")\n",
    "                    if len(parts) == 2:\n",
    "                        text, element_desc = parts\n",
    "                        self._type_text(element_desc, text)\n",
    "                        step_result[\"success\"] = True\n",
    "\n",
    "                elif step.startswith(\"select \"):\n",
    "                    parts = step[7:].strip().split(\" from \")\n",
    "                    if len(parts) == 2:\n",
    "                        option, element_desc = parts\n",
    "                        self._select_option(element_desc, option)\n",
    "                        step_result[\"success\"] = True\n",
    "\n",
    "                # Take screenshot after each step\n",
    "                screenshot_path = f\"{self.config.OUTPUT_DIR}/screenshots/step_{len(page_data['user_flow'])}.png\"\n",
    "                self.driver.save_screenshot(screenshot_path)\n",
    "                step_result[\"screenshot\"] = screenshot_path\n",
    "\n",
    "                # Add current URL\n",
    "                step_result[\"url\"] = self.driver.current_url\n",
    "\n",
    "                # Capture page state after step\n",
    "                step_result[\"page_state\"] = {\n",
    "                    \"title\": self.driver.title,\n",
    "                    \"url\": self.driver.current_url\n",
    "                }\n",
    "\n",
    "                page_data[\"user_flow\"].append(step_result)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error executing step '{step}': {str(e)}\")\n",
    "                step_result[\"error\"] = str(e)\n",
    "                page_data[\"user_flow\"].append(step_result)\n",
    "\n",
    "        return page_data\n",
    "\n",
    "    def save_page_data(self, page_data: Dict[str, Any], filename: Optional[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Save page data to a file.\n",
    "\n",
    "        Args:\n",
    "            page_data (Dict[str, Any]): Page data to save\n",
    "            filename (Optional[str]): Filename to save to (optional)\n",
    "\n",
    "        Returns:\n",
    "            str: Path to the saved file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if page_data is None or empty\n",
    "            if page_data is None:\n",
    "                logger.error(\"Cannot save None page data\")\n",
    "                fallback_path = os.path.join(self.config.OUTPUT_DIR, \"page_data\", f\"error_none_{int(time.time())}.json\")\n",
    "                with open(fallback_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump({\"error\": \"None page data\", \"timestamp\": str(datetime.now())}, f)\n",
    "                return fallback_path\n",
    "\n",
    "            # Create output directory if it doesn't exist\n",
    "            output_dir = os.path.join(self.config.OUTPUT_DIR, \"page_data\")\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # Generate filename from URL if not provided\n",
    "            if not filename:\n",
    "                url = page_data.get(\"url\", \"unknown\")\n",
    "                safe_url = url.replace(\"https://\", \"\").replace(\"http://\", \"\").replace(\"/\", \"_\").replace(\"?\", \"_\")\n",
    "                filename = f\"{safe_url}.json\"\n",
    "\n",
    "            # Ensure the filename has a .json extension\n",
    "            if not filename.endswith(\".json\"):\n",
    "                filename += \".json\"\n",
    "\n",
    "            # Full path to the output file\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            # Create a copy of the page data to avoid modifying the original\n",
    "            data_to_save = page_data.copy()\n",
    "\n",
    "            # Handle large HTML content to avoid token issues later\n",
    "            if \"html_content\" in data_to_save and isinstance(data_to_save[\"html_content\"], str):\n",
    "                html_content = data_to_save[\"html_content\"]\n",
    "                # If HTML content is very large, truncate it\n",
    "                if len(html_content) > 100000:  # 100KB limit\n",
    "                    data_to_save[\"html_content\"] = html_content[:100000] + \"... [truncated]\"\n",
    "                    logger.info(f\"HTML content truncated from {len(html_content)} to 100000 characters\")\n",
    "\n",
    "            # Save the data to a JSON file\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data_to_save, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "            logger.info(f\"Saved page data to {output_path}\")\n",
    "            return output_path\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving page data: {str(e)}\")\n",
    "            # Create a fallback file\n",
    "            fallback_path = os.path.join(self.config.OUTPUT_DIR, \"page_data\", f\"error_{int(time.time())}.json\")\n",
    "            try:\n",
    "                with open(fallback_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    # Include minimal information if page_data is valid\n",
    "                    error_data = {\n",
    "                        \"error\": str(e),\n",
    "                        \"timestamp\": str(datetime.now())\n",
    "                    }\n",
    "\n",
    "                    if isinstance(page_data, dict):\n",
    "                        error_data[\"url\"] = page_data.get(\"url\", \"unknown\")\n",
    "\n",
    "                    json.dump(error_data, f)\n",
    "                return fallback_path\n",
    "            except Exception as inner_e:\n",
    "                logger.error(f\"Error creating fallback file: {str(inner_e)}\")\n",
    "                return \"\"\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the browser.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            self.driver = None\n",
    "            logger.info(\"WebDriver closed\")\n",
    "\n",
    "    def _analyze_layout(self, page_data):\n",
    "        \"\"\"\n",
    "        Analyze the page layout to identify key sections and their relationships.\n",
    "\n",
    "        Args:\n",
    "            page_data (dict): Page data dictionary to be updated with layout information\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # This is a simple implementation - you might want to expand this\n",
    "            layout_data = {\n",
    "                \"viewport_width\": self.driver.execute_script(\"return window.innerWidth\"),\n",
    "                \"viewport_height\": self.driver.execute_script(\"return window.innerHeight\"),\n",
    "                \"sections\": []\n",
    "            }\n",
    "\n",
    "            # Try to identify main sections based on common layout elements\n",
    "            for section_tag in [\"header\", \"nav\", \"main\", \"footer\", \"section\", \"article\", \"aside\"]:\n",
    "                sections = self.driver.find_elements(By.TAG_NAME, section_tag)\n",
    "                for i, section in enumerate(sections):\n",
    "                    try:\n",
    "                        section_id = section.get_attribute(\"id\") or f\"{section_tag}_{i}\"\n",
    "                        rect = section.rect\n",
    "\n",
    "                        # Get the section elements\n",
    "                        inner_elements = section.find_elements(By.XPATH, \".//*\")\n",
    "                        element_count = len(inner_elements)\n",
    "\n",
    "                        # Add section data\n",
    "                        layout_data[\"sections\"].append({\n",
    "                            \"id\": section_id,\n",
    "                            \"tag\": section_tag,\n",
    "                            \"x\": rect[\"x\"],\n",
    "                            \"y\": rect[\"y\"],\n",
    "                            \"width\": rect[\"width\"],\n",
    "                            \"height\": rect[\"height\"],\n",
    "                            \"element_count\": element_count\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        logger.debug(f\"Error analyzing section {section_tag}_{i}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "            # Try to identify content structure using div elements with specific classes\n",
    "            main_divs = self.driver.find_elements(By.XPATH, \"//div[contains(@class, 'main') or contains(@class, 'content') or contains(@class, 'container')]\")\n",
    "            for i, div in enumerate(main_divs):\n",
    "                try:\n",
    "                    div_id = div.get_attribute(\"id\") or div.get_attribute(\"class\") or f\"main_div_{i}\"\n",
    "                    rect = div.rect\n",
    "\n",
    "                    # Check if this seems like a main content area\n",
    "                    if rect[\"width\"] > layout_data[\"viewport_width\"] * 0.5 and rect[\"height\"] > 100:\n",
    "                        layout_data[\"sections\"].append({\n",
    "                            \"id\": div_id,\n",
    "                            \"tag\": \"div\",\n",
    "                            \"x\": rect[\"x\"],\n",
    "                            \"y\": rect[\"y\"],\n",
    "                            \"width\": rect[\"width\"],\n",
    "                            \"height\": rect[\"height\"],\n",
    "                            \"is_main_content\": True\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Error analyzing main div {i}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "            # Add layout data to page data\n",
    "            page_data[\"layout\"] = layout_data\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing layout: {str(e)}\")\n",
    "            # Don't fail the entire process if layout analysis fails\n",
    "            page_data[\"layout\"] = {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
